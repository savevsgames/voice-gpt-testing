{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "664f442a0d8b7166",
   "metadata": {},
   "source": [
    "Set Up API KEYS"
   ]
  },
  {
   "cell_type": "code",
   "id": "c1e6b569215549e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T06:28:23.976807Z",
     "start_time": "2025-02-19T06:28:23.970297Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Access the secrets\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "ELEVENLABS_API_KEY = os.getenv(\"ELEVENLABS_API_KEY\")\n",
    "\n",
    "print(f\"OpenAI Key: {OPENAI_API_KEY[:5]}... (Hidden for security)\")\n",
    "print(f\"11Labs Key: {ELEVENLABS_API_KEY[:5]}... (Hidden for security)\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI Key: sk-pr... (Hidden for security)\n",
      "11Labs Key: sk_06... (Hidden for security)\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "id": "fa3772c76172824e",
   "metadata": {},
   "source": [
    "Initialize OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "id": "322797a33ea2795c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T06:28:36.231532Z",
     "start_time": "2025-02-19T06:28:35.981527Z"
    }
   },
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "id": "12b5d6287cd9caf3",
   "metadata": {},
   "source": [
    "Record Audio Clip (10s test)"
   ]
  },
  {
   "cell_type": "code",
   "id": "99a933e2-949a-4ba9-89c5-b12455f464b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T06:21:07.182744Z",
     "start_time": "2025-02-19T06:20:53.899576Z"
    }
   },
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import wave\n",
    "\n",
    "# List available audio devices\n",
    "devices = sd.query_devices()\n",
    "input_devices = [d for i, d in enumerate(devices) if d[\"max_input_channels\"] > 0]\n",
    "\n",
    "# Print available input devices\n",
    "print(\"\\nAvailable Input Devices:\")\n",
    "for i, device in enumerate(input_devices):\n",
    "    print(f\"{i}: {device['name']} (Max Channels: {device['max_input_channels']})\")\n",
    "\n",
    "# Prompt user for device selection\n",
    "device_index = int(input(\"\\nEnter the number of the device you want to use: \"))\n",
    "selected_device = input_devices[device_index]\n",
    "\n",
    "# Set the selected device\n",
    "sd.default.device = selected_device[\"index\"]\n",
    "channels = min(selected_device[\"max_input_channels\"], 2)  # Use max available channels, up to 2\n",
    "\n",
    "print(f\"\\nUsing device: {selected_device['name']} with {channels} channels.\\n\")\n",
    "\n",
    "# Recording parameters\n",
    "duration = 10  # seconds\n",
    "sample_rate = 44100\n",
    "\n",
    "print(\"Recording...\")\n",
    "audio_data = sd.rec(int(sample_rate * duration), samplerate=sample_rate, channels=channels, dtype=np.int16)\n",
    "sd.wait()\n",
    "print(\"Recording complete.\")\n",
    "\n",
    "# Save to a WAV file\n",
    "filename = \"user_recording.wav\"\n",
    "with wave.open(filename, 'wb') as wf:\n",
    "    wf.setnchannels(channels)\n",
    "    wf.setsampwidth(2)\n",
    "    wf.setframerate(sample_rate)\n",
    "    wf.writeframes(audio_data.tobytes())\n",
    "\n",
    "print(f\"Saved recording as {filename}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available Input Devices:\n",
      "0: Microsoft Sound Mapper - Input (Max Channels: 2)\n",
      "1: Microphone (3- Afterglow AG9+ W (Max Channels: 1)\n",
      "2: Microphone (Realtek(R) Audio) (Max Channels: 2)\n",
      "3: Primary Sound Capture Driver (Max Channels: 2)\n",
      "4: Microphone (3- Afterglow AG9+ Wireless Headset) (Max Channels: 1)\n",
      "5: Microphone (Realtek(R) Audio) (Max Channels: 2)\n",
      "6: Microphone (Realtek(R) Audio) (Max Channels: 2)\n",
      "7: Microphone (3- Afterglow AG9+ Wireless Headset) (Max Channels: 1)\n",
      "8: Microphone (Afterglow AG9+ Wireless Headset) (Max Channels: 1)\n",
      "9: Stereo Mix (Realtek HD Audio Stereo input) (Max Channels: 2)\n",
      "10: Microphone (Realtek HD Audio Mic input) (Max Channels: 2)\n",
      "11: Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\r\n",
      ";(MusiBaby-M68)) (Max Channels: 1)\n",
      "12: Microphone (Voicemod VAD Wave) (Max Channels: 2)\n",
      "13: Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\r\n",
      ";(YT18)) (Max Channels: 1)\n",
      "14: Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\r\n",
      ";(T17)) (Max Channels: 1)\n",
      "\n",
      "Using device: Microphone (3- Afterglow AG9+ W with 1 channels.\n",
      "\n",
      "Recording...\n",
      "Recording complete.\n",
      "Saved recording as user_recording.wav\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "id": "f0e428e39977d8fe",
   "metadata": {},
   "source": [
    "Transcribe Audio to Text - WhisperAI"
   ]
  },
  {
   "cell_type": "code",
   "id": "dcc895c9b5cb1c92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T06:21:14.236658Z",
     "start_time": "2025-02-19T06:21:10.693878Z"
    }
   },
   "source": [
    "def transcribe_audio(audio_path):\n",
    "    with open(audio_path, \"rb\") as audio_file:\n",
    "        transcript = client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\",\n",
    "            file=audio_file\n",
    "        )\n",
    "    return transcript.text\n",
    "\n",
    "transcribed_text = transcribe_audio(\"user_recording.wav\")\n",
    "print(\"Transcribed Text:\", transcribed_text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribed Text: La-da-dee-dee-dee. Hi, my name is Greg and this is Greg Radio, the best place that you can find any kind of radio ever. It's amazing.\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "id": "32cd0ecea0758b59",
   "metadata": {},
   "source": [
    "Generate AI Response with transcribed_text"
   ]
  },
  {
   "cell_type": "code",
   "id": "6151890fad17e0be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T06:21:40.346369Z",
     "start_time": "2025-02-19T06:21:23.015135Z"
    }
   },
   "source": [
    "def get_gpt_response(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "response_text = get_gpt_response(transcribed_text)\n",
    "print(\"GPT Response:\", response_text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT Response: Welcome back to another episode! Today, we have a variety of content lined up. As you all know, we love to delve into various topics here at Greg Radio; we take you from the caves of history to the peaks of future technology, jazz up your mood with some music, fill your heart with inspiring stories, and make you smarter with intriguing trivia.\n",
      "\n",
      "We have a brilliant interview lined up for 10 AM, where we are talking to renowned author, Rebecca York, who recently won the Booker Prize for her thought-provoking book 'Eclipse Whisper'. She will share insights into her writing process, inspirations, and give us a sneak peek into her next novel.\n",
      "\n",
      "Masterchef Ruth Madison will join us at 1 PM and take us through some delectable recipes right from her cookbook. Stay tuned while she adds a sizzle to your afternoon with her signature dish.\n",
      "\n",
      "Do you feel the need to let out some steam after a long day at work? Then, don't forget to join our popular evening segment - 'Rant it out' at 6 PM where we invite callers to vent and share their daily life antics. Trust me, the stories are an absolute riot!\n",
      "\n",
      "And, don't forget about our late-night music special - 'Crescendo Night Waves' at 9 PM where we play a soothing blend of classical melodies and chill pop to help you relax.\n",
      "\n",
      "Mark your calendars and tune in to Greg Radio for an exciting day full of entertainment, information, and fun! The party begins in a few minutes, so buckle up and get ready for an aural treat! As always, this is Greg, your amiable host, ready to make your day a little better, one radio segment at a time.\n",
      "\n",
      "And remember, there's no better place to be than Greg Radio, your one-stop-shop for all things radio. Happy listening!\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "id": "d0df52a8c06d1496",
   "metadata": {},
   "source": [
    "11 Labs text-to-speech"
   ]
  },
  {
   "cell_type": "code",
   "id": "b71c1892098ad6e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T06:42:27.086220Z",
     "start_time": "2025-02-19T06:42:02.004594Z"
    }
   },
   "source": [
    "import requests\n",
    "\n",
    "ELEVENLABS_API_KEY = os.getenv(\"ELEVENLABS_API_KEY\")\n",
    "\n",
    "print(\"Loaded API Key:\", ELEVENLABS_API_KEY[:5], \"********\")\n",
    "\n",
    "# API request to get voices\n",
    "def get_voice_ids():\n",
    "    url = \"https://api.elevenlabs.io/v1/voices\"\n",
    "    headers = {\"xi-api-key\": ELEVENLABS_API_KEY}\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        voices = response.json()[\"voices\"]\n",
    "        for voice in voices:\n",
    "            print(f\"Voice Name: {voice['name']}, Voice ID: {voice['voice_id']}\")\n",
    "        return voices\n",
    "    else:\n",
    "        print(\"Error fetching voices:\", response.text)\n",
    "        return None\n",
    "\n",
    "# Get valid voice IDs\n",
    "voice_options = get_voice_ids()\n",
    "voices = [v for i, v in enumerate(voice_options) if v[\"voice_id\"] in v]\n",
    "\n",
    "print(\"\\nVoice Options\")\n",
    "for i, voice in enumerate(voice_options):\n",
    "    print(f\"{i}: {voice['name']} (ID: {voice['voice_id']})\")\n",
    "\n",
    "# Prompt user for device selection\n",
    "voice_index = int(input(\"\\nEnter the number of the voice you want to use: \"))\n",
    "selected_voice = voice_options[voice_index][\"voice_id\"]\n",
    "\n",
    "\n",
    "def text_to_speech_11labs(text, voice_id=selected_voice):\n",
    "    url = f\"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}\"\n",
    "    headers = {\"xi-api-key\": ELEVENLABS_API_KEY, \"Content-Type\": \"application/json\"}\n",
    "    data = {\"text\": text, \"model_id\": \"eleven_monolingual_v1\"}\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        with open(\"output_speech.mp3\", \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(\"Generated Speech: output_speech.mp3\")\n",
    "    else:\n",
    "        print(\"Error:\", response.text)\n",
    "\n",
    "text_to_speech_11labs(response_text)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded API Key: sk_06 ********\n",
      "Voice Name: Aria, Voice ID: 9BWtsMINqrJLrRacOk9x\n",
      "Voice Name: Roger, Voice ID: CwhRBWXzGAHq8TQ4Fs17\n",
      "Voice Name: Sarah, Voice ID: EXAVITQu4vr4xnSDxMaL\n",
      "Voice Name: Laura, Voice ID: FGY2WhTYpPnrIDTdsKH5\n",
      "Voice Name: Charlie, Voice ID: IKne3meq5aSn9XLyUdCD\n",
      "Voice Name: George, Voice ID: JBFqnCBsd6RMkjVDRZzb\n",
      "Voice Name: Callum, Voice ID: N2lVS1w4EtoT3dr4eOWO\n",
      "Voice Name: River, Voice ID: SAz9YHcvj6GT2YYXdXww\n",
      "Voice Name: Liam, Voice ID: TX3LPaxmHKxFdv7VOQHJ\n",
      "Voice Name: Charlotte, Voice ID: XB0fDUnXU5powFXDhCwa\n",
      "Voice Name: Alice, Voice ID: Xb7hH8MSUJpSbSDYk0k2\n",
      "Voice Name: Matilda, Voice ID: XrExE9yKIg1WjnnlVkGX\n",
      "Voice Name: Will, Voice ID: bIHbv24MWmeRgasZH58o\n",
      "Voice Name: Jessica, Voice ID: cgSgspJ2msm6clMCkdW9\n",
      "Voice Name: Eric, Voice ID: cjVigY5qzO86Huf0OWal\n",
      "Voice Name: Chris, Voice ID: iP95p4xoKVk53GoZ742B\n",
      "Voice Name: Brian, Voice ID: nPczCjzI2devNBz1zQrb\n",
      "Voice Name: Daniel, Voice ID: onwK4e9ZLuTAKqWW03F9\n",
      "Voice Name: Lily, Voice ID: pFZP5JQG7iQjIQuC4Bku\n",
      "Voice Name: Bill, Voice ID: pqHfZKP75CvOlQylNhV4\n",
      "\n",
      "Voice Options\n",
      "0: Aria (ID: 9BWtsMINqrJLrRacOk9x)\n",
      "1: Roger (ID: CwhRBWXzGAHq8TQ4Fs17)\n",
      "2: Sarah (ID: EXAVITQu4vr4xnSDxMaL)\n",
      "3: Laura (ID: FGY2WhTYpPnrIDTdsKH5)\n",
      "4: Charlie (ID: IKne3meq5aSn9XLyUdCD)\n",
      "5: George (ID: JBFqnCBsd6RMkjVDRZzb)\n",
      "6: Callum (ID: N2lVS1w4EtoT3dr4eOWO)\n",
      "7: River (ID: SAz9YHcvj6GT2YYXdXww)\n",
      "8: Liam (ID: TX3LPaxmHKxFdv7VOQHJ)\n",
      "9: Charlotte (ID: XB0fDUnXU5powFXDhCwa)\n",
      "10: Alice (ID: Xb7hH8MSUJpSbSDYk0k2)\n",
      "11: Matilda (ID: XrExE9yKIg1WjnnlVkGX)\n",
      "12: Will (ID: bIHbv24MWmeRgasZH58o)\n",
      "13: Jessica (ID: cgSgspJ2msm6clMCkdW9)\n",
      "14: Eric (ID: cjVigY5qzO86Huf0OWal)\n",
      "15: Chris (ID: iP95p4xoKVk53GoZ742B)\n",
      "16: Brian (ID: nPczCjzI2devNBz1zQrb)\n",
      "17: Daniel (ID: onwK4e9ZLuTAKqWW03F9)\n",
      "18: Lily (ID: pFZP5JQG7iQjIQuC4Bku)\n",
      "19: Bill (ID: pqHfZKP75CvOlQylNhV4)\n",
      "Generated Speech: output_speech.mp3\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "id": "70ddeaf4b86b56a4",
   "metadata": {},
   "source": [
    "Download Audio - in Notebook"
   ]
  },
  {
   "cell_type": "code",
   "id": "14d9c93161b32eb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T06:42:35.660751Z",
     "start_time": "2025-02-19T06:42:35.654673Z"
    }
   },
   "source": [
    "import IPython.display as display\n",
    "\n",
    "# Display a download link in Jupyter Notebook\n",
    "def download_audio(filename=\"output_speech.mp3\"):\n",
    "    return display.FileLink(filename)\n",
    "\n",
    "download_audio()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C:\\Users\\gregc\\PycharmProjects\\VoiceGPTtesting\\notebooks\\output_speech.mp3"
      ],
      "text/html": [
       "<a href='output_speech.mp3' target='_blank'>output_speech.mp3</a><br>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
